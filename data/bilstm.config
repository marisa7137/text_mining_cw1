# Different Settings for training, testing developing and other settings
[param]
path_train : ../data/train.txt
path_dev : ../data/dev.txt
path_test : ../data/test.txt
# glove path
glove_weight_path: ../data/glove_weight_300d.npy
glove_vocab_path: ../data/glove_vocab_300d.txt

# stop_words
stop_words: ../data/stopwords.txt

# label files
fine_label: ../data/fine_labels.txt
coarse_label: ../data/coarse_labels.txt

# vocab
vocab: ../data/vocab.txt


# train labels
train_5500: ../data/train_5500.label.txt

# utilities
acc_bilstm_coase: biLSTM_Utilities/acc_biLSTM_COASE.txt
acc_bilstm_fine: biLSTM_Utilities/acc_biLSTM_fineclass.txt
bilstm_coase_pth: ../data/bilstm_coarse.bilstm
bilstm_fine_pth: ../data/bilstm_fine.bilstm
f1_bilstm_fine: biLSTM_Utilities/f1_biLSTM_fineclass.txt
f1_bilstm_coase: biLSTM_Utilities/f1_biLSTM_COASE.txt
loss_bilstm_coase: biLSTM_Utilities/loss_biLSTM_COASE.txt
loss_bilstm_fine: biLSTM_Utilities/loss_biLSTM_fineclass.txt

# text parser

# model
model: bilstm
# fine | coarse
class_label: fine
# True | False
pretrain : True
# freeze
freeze : False

# output
fine_output: ../data/fine_output.txt
coarse_output: ../data/coarse_output.txt


# learning rate
lr: 7e-3
epoch: 10
batch: 500
# word embedding size:
embedding_dim: 300
# hidden layer dim
hidden_dim: 256
# hidden layer size
hidden_layer: 50
